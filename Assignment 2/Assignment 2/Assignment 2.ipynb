{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIP Assignment 2\n",
    "\n",
    "## Garima Jain\n",
    "## M.Tech AI\n",
    "## 18MCMI14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Search the web for Colour Halftoning algorithms. Select one of them and write a detailed report on it OR implement the selected algorithm and show results on the test images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing CMY Ordered Dot Dithering Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "output_size = 16 x input_size \n",
    "4x4 CMY color dithered mask \n",
    "set threshold, which pixels will be set and which not\n",
    "for each pixel in input image, calculate #dots to be put for C,M,Y acc. to corr. pixel vlaues\n",
    "'''\n",
    "\n",
    "def cmy_color_dithering(image,result_image_name):\n",
    "    output_img = np.zeros((image.shape[0]*4, image.shape[1]*4, 3), np.uint8)\n",
    "\n",
    "    #indexes for each in priority order according to Bayer's mask\n",
    "    ordered_c_ind = [[2,2],[0,2],[2,0],[3,1],[2,3]] \n",
    "    ordered_m_ind = [[1,1],[1,3],[0,1],[0,3],[2,1],[1,2]]\n",
    "    ordered_y_ind = [[0,0],[3,3],[1,0],[3,2],[3,0]]\n",
    "    \n",
    "    \n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            c_val = 255 - image[i,j,2]\n",
    "            m_val = 255 - image[i,j,1]\n",
    "            y_val = 255 - image[i,j,0]\n",
    "            \n",
    "            #find number of dots to be set for C,M,Y using unitary method \n",
    "            c_dots = ( len(ordered_c_ind) * c_val ) // 255\n",
    "            m_dots = ( len(ordered_m_ind) * m_val ) // 255\n",
    "            y_dots = ( len(ordered_y_ind) * y_val ) // 255\n",
    "            \n",
    "            x,y = i*4, j*4\n",
    "            for k in range(c_dots): # for cyan, set B and G \n",
    "                output_img[x+ordered_c_ind[k][0],y+ordered_c_ind[k][1]] = [255,255,0]\n",
    "\n",
    "            for k in range(m_dots): # for magenta, set B and R\n",
    "                output_img[x+ordered_m_ind[k][0],y+ordered_m_ind[k][1]] = [255,0,255]\n",
    "            \n",
    "            for k in range(y_dots): # for yellow, set G and R\n",
    "                output_img[x+ordered_y_ind[k][0],y+ordered_y_ind[k][1]] = [0,255,255]\n",
    "    \n",
    "    cv.imwrite(result_image_name,output_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "mask:\n",
    "[Y1,M3,C2,M4]\n",
    "[Y3,M1,M6,M2]\n",
    "[C3,M5,C1,C5]\n",
    "[Y5,C4,Y4,Y2]\n",
    "\n",
    "C = W-R = G+B\n",
    "M = W-G = R+B\n",
    "Y = W-B = R+G\n",
    "'''\n",
    "image = cv.imread('Test_data/waterplane.ppm')\n",
    "cmy_color_dithering(image,'Q1.CMYDithering/waterplane.ppm')\n",
    "\n",
    "image = cv.imread('Test_data/orange-flower.ppm')\n",
    "cmy_color_dithering(image,'Q1.CMYDithering/orange-flower.png')\n",
    "\n",
    "image = cv.imread('Test_data/fall-colours.jpg')\n",
    "cmy_color_dithering(image,'Q1.CMYDithering/fall-colours.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output images are in folder Q1.CMYDithering.\n",
    "The mask I used is shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Try coming up with your own error diffusion coefficients and implement the standard error-diffusion algorithm. Compare the performance of your coefficients against Floyd-Steinberg's on this image. Discuss the patterns visible in yours and in Floyd-Steinberg's at the various gray levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_diffusion_algo(image, indexes, num_of_indexes, coeffs, result_image):\n",
    "    new_image = image.copy()\n",
    "    for i in range(1,new_image.shape[0]-2):\n",
    "        for j in range(1,new_image.shape[1]-2):\n",
    "            error = 0\n",
    "            if new_image[i][j] < 128 : # threshold for binarisation - 128\n",
    "                error = new_image[i][j]\n",
    "                new_image[i][j] = 0                \n",
    "            else:\n",
    "                error = new_image[i][j] - 255\n",
    "                new_image[i][j] = 255\n",
    "            for k in range(num_of_indexes):\n",
    "                new_image[i+indexes[k][0]][j+indexes[k][1]] = np.clip(\n",
    "                                                                (new_image[i+indexes[k][0]][j+indexes[k][1]]\\\n",
    "                                                                + coeffs[k] * error), 0, 255)    \n",
    "#     new_image = np.uint8(new_image)\n",
    "    cv.imwrite(result_image, new_image)\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv.imread('Test_data/ed-eg.png',0)\n",
    "\n",
    "floyd_steinberg_indexes = [[0,1], [1,1], [1,0], [1,-1]]\n",
    "floyd_steinberg_coeffs = [7 / 16, 1 / 16, 5 / 16, 3 / 16]\n",
    "fd_num_of_indexes = 4\n",
    "error_diffusion_algo(image, floyd_steinberg_indexes, fd_num_of_indexes, floyd_steinberg_coeffs, \"Q2.Results/FloydSteinbergDiffused.png\")\n",
    "\n",
    "my_diffusion_indexes = [[0,1], [1,1], [1,0],[0,2], [2,2], [2,0]]\n",
    "my_num_of_indexes = 6\n",
    "my_diffused_image = error_diffusion_algo(image, my_diffusion_indexes, my_num_of_indexes, my_diffusion_coeffs, \"Q2.Results/MyDiffused.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output images are in folder Ques2.Results\n",
    "\n",
    "Error diffusing algorithm is a type of half toning in which error is diffused to other pixels, if pixel value < 127, then error is pixel value,else it's pixel value-255. Error is the value by which pixel value deviates from threshold, which is 127. Error is diffused to neighboring pixels and then if it's value is<127, then pixel is not set, i.e black dot else white dot is put. \n",
    "Here, first I have implemented error diffuing algorithm with Floyd Steinberg coefficients and then with my own set of coefficients. I am diffusing error to 2 right pixels, 2 bottom pixels and 2 bottom right diagonal pixels. \n",
    "\n",
    "Difference in the patterns visible in Floyd Steinberg algorithm and one with my coefficients:In the upper half of the image, floyd steinberg result has some patterns throughout, there are no visible patterns in mine though, it's quite smooth. However, in the lower half of the image, verticals line can be seen in my output at various gray levels while Floyd Steinberg has small patterns as compared to mine. Since I am diffusing error to 2 pixels, elongated patterns are visible in mine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. \n",
    "### (a).Implement an algorithm to simulate the grayscale output from a colour filter array. The function prototype is image colour_filter (image, filter).That is, it takes an input colour image and a colour filter as parameters and returns a grayscale image. \n",
    "### (b). Implement a demosaicking algorithm with the prototype image demosaic (image, filter).The input image is a grayscale image output by the colour_filter algorithm and the corresponding filter array; the output is a colour image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Apply color filter array on color image to get grayscale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_to_grayscale(image, color_filter, result_image):\n",
    "    neighbors = [[0,0], [0,1], [1,0], [1,1]]\n",
    "    new_image = np.zeros((image.shape[0],image.shape[1]))\n",
    "    # pass 2x2 filter over the image, for each filter component value, \n",
    "    # retain that component value in pixel\n",
    "    for i in range(0, image.shape[0]-2, 2):\n",
    "        for j in range(0, image.shape[1]-2, 2):\n",
    "            for k in range(0, 4):\n",
    "                new_image[i+neighbors[k][0]][j+neighbors[k][1]] = image[i+k][j+k][color_filter[k]]\n",
    "    cv.imwrite(result_image, new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_filter1 = [1, 2, 0, 1] # Bayer's mask which Canon uses\n",
    "color_filter2 = [2, 1, 1, 0] # Bayer's mask which other manufaturers use\n",
    "\n",
    "image = cv.imread('Test_data/orange-flower.ppm')\n",
    "image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "color_filter_2grayscale(image, color_filter1,'Q3.Grayscale_image_results/filter1_orange_flower.jpg')\n",
    "color_filter_2grayscale(image, color_filter2,'Q3.Grayscale_image_results/filter2_orange_flower.jpg')\n",
    "\n",
    "image = cv.imread('Test_data/fall-colours.jpg')\n",
    "image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "color_filter_2grayscale(image, color_filter1,'Q3.Grayscale_image_results/filter1_fall_colors.jpg')\n",
    "color_filter_2grayscale(image, color_filter2,'Q3.Grayscale_image_results/filter2_fall_colors.jpg')\n",
    "\n",
    "image = cv.imread('Test_data/waterplane.ppm')\n",
    "image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "color_filter_2grayscale(image, color_filter1,'Q3.Grayscale_image_results/filter1_waterplane.jpg')\n",
    "color_filter_2grayscale(image, color_filter2,'Q3.Grayscale_image_results/filter2_waterplane.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output images are in folder Q3.Grayscale_image_results.\n",
    "\n",
    "I have used both the filters, the one which Canon uses and the one which other manufacturers use. There are no visible changes at normal level though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Demosaicking algorithm - apply color filter array on grayscale image - convert to color image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale_to_color(image, color_filter, result_image):\n",
    "    '''\n",
    "    pass the filter over the pixels, set values for each channel corr. to mask \n",
    "    '''\n",
    "    new_image = np.zeros((image.shape[0], image.shape[1], 3))    \n",
    "    for i in range(0, image.shape[0]-1, 1):\n",
    "        for j in range(0, image.shape[1]-1, 1):\n",
    "            r = np.where(color_filter == 0)\n",
    "            g = np.where(color_filter == 1)\n",
    "            b = np.where(color_filter == 2)\n",
    "            \n",
    "            for x,y in zip(r[0],r[1]):\n",
    "                new_image[i][j][2] = image[i+x][j+y] # red component\n",
    "            \n",
    "            for x,y in zip(g[0],g[1]):\n",
    "                new_image[i][j][1] += image[i+x][j+y]\n",
    "            new_image[i][j][1] = new_image[i][j][1] / 2\n",
    "            \n",
    "            for x,y in zip(b[0],b[1]):\n",
    "                new_image[i][j][0] = image[i+x][j+y] # blue\n",
    "            \n",
    "            color_filter = np.roll(color_filter, shift=1, axis=1)\n",
    "        \n",
    "        color_filter = np.roll(color_filter, shift=1, axis=1)\n",
    "        color_filter = np.roll(color_filter, shift=1, axis=0)\n",
    "    cv.imwrite(result_image,new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_filter1 = np.array([[1,2],[0,1]]) # Bayer's mask which Canon uses\n",
    "color_filter2 = np.array([[2,1],[1,0]]) \n",
    "\n",
    "image1 = cv.imread('Q3.Grayscale_image_results/filter1_fall_colors.jpg',0)\n",
    "image2 = cv.imread('Q3.Grayscale_image_results/filter2_fall_colors.jpg',0)\n",
    "grayscale_to_color(image1, color_filter1,'Q3.Demosaicking_results/filter1_fall_colors.png')\n",
    "grayscale_to_color(image2, color_filter2,'Q3.Demosaicking_results/filter2_fall_colors.png')\n",
    "\n",
    "image1 = cv.imread('Q3.Grayscale_image_results/filter1_orange_flower.jpg',0)\n",
    "image2 = cv.imread('Q3.Grayscale_image_results/filter2_orange_flower.jpg',0)\n",
    "grayscale_to_color(image1, color_filter1,'Q3.Demosaicking_results/filter1_orange_flower.png')\n",
    "grayscale_to_color(image2, color_filter2,'Q3.Demosaicking_results/filter2_orange_flower.png')\n",
    "\n",
    "image1 = cv.imread('Q3.Grayscale_image_results/filter1_waterplane.jpg',0)\n",
    "image2 = cv.imread('Q3.Grayscale_image_results/filter2_waterplane.jpg',0)\n",
    "grayscale_to_color(image1, color_filter1,'Q3.Demosaicking_results/filter1_waterplane.png')\n",
    "grayscale_to_color(image2, color_filter2,'Q3.Demosaicking_results/filter2_waterplane.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting images are in folder Q3.Demosaicking_results.\n",
    "\n",
    "Again, I applied the algorithm using both the filters. The images produced using Filter 2 seem to be more saturated than the ones produced using filter1. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
